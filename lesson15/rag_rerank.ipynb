{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создаем ретривер на chroma и  bge-small-en-v1.5\n",
    "2. Делаем RAG с моделью LLM через библиотку Hugging Face. Возможность получить от модели вариативный вывод есть только transformers, поэтому мы сильно ограничены. В этой тетрадке я использую модель gtp2. У меня почему-то локально не хочет скачивать кватизированные модели. \n",
    "3. Создает пустой графовый ретривер, добавляя в него заранее сгенерированные триплеты. \n",
    "4. Создаем KG-ретривер, котрорый будет возвращать релевантные к запросу триплеты.\n",
    "\n",
    "Какая логика:\n",
    "1. Мы отправляем запрос в RAG-сеттинг и получаем от модели несколько ответов. \n",
    "2. Отправляем этот же запрос в KG-ретривер, чтобы получить релеватные триплеты.\n",
    "3. Реранк Ответов модели:\n",
    " * Первый вариант: Получаем векторное представление найденных триплетов и сравниваем его с эмббедингами ответов. Предполагаем, что эмббединг наилучшего ответа модели будет наиболее близок к эмббедингу триплетов. \n",
    " * Второй вариант: Просим большую модель с учетом триплетов реранжировать ответы изначальной модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/Repo/Alexandra/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import chromadb\n",
    "from llama_index.core import ServiceContext, StorageContext\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from llama_index.llms.openai import OpenAI as OpenAIllm\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import yaml\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры скрипта\n",
    "\n",
    "DOMAIN = 'movie'\n",
    "# DOMAIN = 'computer'\n",
    "# DOMAIN = 'nature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secrets.yaml', 'r') as f:\n",
    "    secrets = yaml.safe_load(f)\n",
    "\n",
    "openai_key = secrets['openai_key']\n",
    "\n",
    "os.environ['OPEN_AI_KEY'] = openai_key\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>question</th>\n",
       "      <th>rag_0</th>\n",
       "      <th>rag_1</th>\n",
       "      <th>rag_2</th>\n",
       "      <th>uniq_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chapleau River is in the James Bay drainage ba...</td>\n",
       "      <td>What is the main tributary of Kapuskasing Lake?</td>\n",
       "      <td>Chapleau River</td>\n",
       "      <td>Chapleau River is the main tributary of Kapusk...</td>\n",
       "      <td>Chapleau River</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The mountains classification was won by Nicola...</td>\n",
       "      <td>Who won the mountains classification in the To...</td>\n",
       "      <td>Juan Felipe Osorio won the mountains classific...</td>\n",
       "      <td>Juan Felipe Osorio won the mountains classific...</td>\n",
       "      <td>Juan Felipe Osorio won the mountains classific...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The wreathed hornbill (Rhyticeros undulatus), ...</td>\n",
       "      <td>What is the distribution of the wreathed hornb...</td>\n",
       "      <td>The wreathed hornbill is found in forests from...</td>\n",
       "      <td>The wreathed hornbill species is found in fore...</td>\n",
       "      <td>The distribution of the wreathed hornbill spec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The podium placings were completed by another ...</td>\n",
       "      <td>Who finished third on Willunga Hill and took f...</td>\n",
       "      <td>Tom-Jelte Slagter of Team Dimension Data.</td>\n",
       "      <td>Tom-Jelte Slagter of Team Dimension Data finis...</td>\n",
       "      <td>Tom-Jelte Slagter of Team Dimension Data.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Australian swiftlet (Aerodramus terraeregi...</td>\n",
       "      <td>What is the scientific name of the Australian ...</td>\n",
       "      <td>Aerodramus terraereginae</td>\n",
       "      <td>Aerodramus terraereginae.</td>\n",
       "      <td>The scientific name of the Australian swiftlet...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  \\\n",
       "0  Chapleau River is in the James Bay drainage ba...   \n",
       "1  The mountains classification was won by Nicola...   \n",
       "2  The wreathed hornbill (Rhyticeros undulatus), ...   \n",
       "3  The podium placings were completed by another ...   \n",
       "4  The Australian swiftlet (Aerodramus terraeregi...   \n",
       "\n",
       "                                            question  \\\n",
       "0    What is the main tributary of Kapuskasing Lake?   \n",
       "1  Who won the mountains classification in the To...   \n",
       "2  What is the distribution of the wreathed hornb...   \n",
       "3  Who finished third on Willunga Hill and took f...   \n",
       "4  What is the scientific name of the Australian ...   \n",
       "\n",
       "                                               rag_0  \\\n",
       "0                                     Chapleau River   \n",
       "1  Juan Felipe Osorio won the mountains classific...   \n",
       "2  The wreathed hornbill is found in forests from...   \n",
       "3          Tom-Jelte Slagter of Team Dimension Data.   \n",
       "4                           Aerodramus terraereginae   \n",
       "\n",
       "                                               rag_1  \\\n",
       "0  Chapleau River is the main tributary of Kapusk...   \n",
       "1  Juan Felipe Osorio won the mountains classific...   \n",
       "2  The wreathed hornbill species is found in fore...   \n",
       "3  Tom-Jelte Slagter of Team Dimension Data finis...   \n",
       "4                          Aerodramus terraereginae.   \n",
       "\n",
       "                                               rag_2  uniq_count  \n",
       "0                                     Chapleau River           2  \n",
       "1  Juan Felipe Osorio won the mountains classific...           2  \n",
       "2  The distribution of the wreathed hornbill spec...           3  \n",
       "3          Tom-Jelte Slagter of Team Dimension Data.           2  \n",
       "4  The scientific name of the Australian swiftlet...           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join('artifacts', DOMAIN, 'eval_dataset.csv')\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иницилизируем модель для получения эмббедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformerEmbeddingFunction(model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "                                                device='cpu'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отдельном файле rag_cloud.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG ретривер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем три ретривера для трех графов: fine tuned, fine tuned postprocessed, ground truth.<br>\n",
    "Cохраняем в query_engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если требуется, то комментарии ретривера есть в сходном файле rag_rerank.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_datases = {\n",
    "    'ft': os.path.join('artifacts', DOMAIN, 'triples_ft.jsonl'),\n",
    "    'ftpp': os.path.join('artifacts', DOMAIN, 'triples_ft_pp.jsonl'),\n",
    "    'gt': os.path.join('artifacts', DOMAIN, 'triples_gt.jsonl'),\n",
    "}\n",
    "\n",
    "query_engines = {}\n",
    "\n",
    "for k, file_path in kg_datases.items():\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "        \n",
    "    triplets = []\n",
    "    for i_line in data:\n",
    "        i_line = json.loads(i_line)\n",
    "        for i_triplet in i_line['triples']:\n",
    "            if 'sub' in i_triplet and 'rel' in i_triplet and 'obj' in i_triplet:\n",
    "                prep_triplet = [i_triplet['sub'], i_triplet['rel'], i_triplet['obj']]\n",
    "                triplets.append(prep_triplet)\n",
    "\n",
    "    llm = OpenAIllm(temperature=0, \n",
    "                #model=\"gpt-4-1106-preview\", \n",
    "                openai_api_key = openai_key)\n",
    "\n",
    "    graph_store = SimpleGraphStore()\n",
    "\n",
    "    for i_triplet in triplets:\n",
    "        graph_store.upsert_triplet(i_triplet[0], i_triplet[1], i_triplet[2])\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "    graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "        storage_context=storage_context,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        graph_rag_retriever,\n",
    "    )\n",
    "\n",
    "    query_engines[k] = query_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реранжирование ответов модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_outputs_cosine(model_outputs, kg_response):\n",
    "    \"\"\"\n",
    "    Функция для переранжировки ответов модели на основе косинусного сходства с триплетами из базы знаний.\n",
    "\n",
    "    Аргументы:\n",
    "    - model_outputs: список ответов модели\n",
    "    - kg_response: ответ из базы знаний\n",
    "\n",
    "    Возвращает:\n",
    "    - Отсортированный список текстовых выводов на основе косинусного сходства с триплетами из базы знаний.\n",
    "    \"\"\"\n",
    "    if kg_response.source_nodes:\n",
    "        triplets_set = set()\n",
    "        for i_triplet in kg_response.source_nodes[0].metadata['kg_rel_text']:\n",
    "            triplets_set.update(set(ast.literal_eval(i_triplet)))\n",
    "        triplets_string = ' '.join(triplets_set)\n",
    "        # triplets_string\n",
    "\n",
    "        triplets_emb = embed_model(triplets_string)[0]\n",
    "        outputs_emb = embed_model(model_outputs)\n",
    "\n",
    "        similarities = cosine_similarity(outputs_emb, [triplets_emb])\n",
    "        # print(similarities)\n",
    "\n",
    "        sorted_indices = np.argsort(-similarities[:, 0]) \n",
    "\n",
    "        sorted_texts = [model_outputs[index] for index in sorted_indices]\n",
    "        return sorted_texts\n",
    "    \n",
    "    # return \"Не удалось найти триплеты.\"\n",
    "    # если нет триплетов, то означает, что улучшить не получилось, ответ не меняется\n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим по датасету. Реранжируем только различающиеся ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [09:04<00:00,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдены знания в {'ft': 40, 'ftpp': 33, 'gt': 63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_cnt = {'ft': 0, 'ftpp': 0, 'gt': 0}\n",
    "\n",
    "df['cosine_reranked_ft'] = None\n",
    "df['cosine_reranked_ftpp'] = None\n",
    "df['cosine_reranked_gt'] = None\n",
    "\n",
    "for index in tqdm(df[df.uniq_count > 1].index):\n",
    "    query = df.loc[index, 'question']\n",
    "    output_texts = [df.loc[index, 'rag_0'], df.loc[index, 'rag_1'], df.loc[index, 'rag_2']]\n",
    "\n",
    "    for k, query_engine in query_engines.items():\n",
    "        response = query_engine.query(query)\n",
    "        if response.source_nodes:\n",
    "            reranked_outputs = rerank_outputs_cosine(output_texts, response)\n",
    "            success_cnt[k] += 1\n",
    "        else:\n",
    "            reranked_outputs = output_texts\n",
    "        df.loc[index, f'cosine_reranked_{k}'] = reranked_outputs[0]\n",
    "\n",
    "df.to_csv(dataset_path, index=False)\n",
    "\n",
    "print(f'Найдены знания в {success_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количесво изменений ответов:\n",
      "k: 20\n",
      "k: 16\n",
      "k: 34\n"
     ]
    }
   ],
   "source": [
    "print('Количесво изменений ответов:')\n",
    "for k in query_engines.keys():\n",
    "    x = ((df.uniq_count > 1) & (df.rag_0 != df[f'cosine_reranked_{k}'])).sum()\n",
    "    print(f'{k}: {x}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_template = \"\"\"You are provided a question and list of answers. You are to rank the answers in order of relevance to the facts in provided triplets. \n",
    "If an answer is not relevant to the triplets and question, rank it last. If an answer is relevant to the question and triplets, rank it based on how relevant it is.\n",
    "\n",
    "Your output must be a list of the answers in order of relevance to the question and triplets.\n",
    "####################\n",
    "Question: {question}\n",
    "Triplets: {triplets}\n",
    "Answers: {answers}\n",
    "####################\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_outputs_llm(query, model_outputs, kg_response, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Функция для переранжировки ответов модели на основе llm сходства с триплетами из базы знаний.\n",
    "\n",
    "    Аргументы:\n",
    "    - query: запрос\n",
    "    - model_outputs: список ответов модели\n",
    "    - kg_response: ответ из базы знаний\n",
    "\n",
    "    Возвращает:\n",
    "    - Отсортированный список текстовых выводов \n",
    "    \"\"\"\n",
    "\n",
    "    if kg_response.source_nodes:\n",
    "        prompt = rerank_template.format(\n",
    "            question=query, \n",
    "            triplets=kg_response.source_nodes[0].metadata['kg_rel_text'], \n",
    "            answers=model_outputs)\n",
    "\n",
    "        gpt_response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        gpt_response_text = gpt_response.choices[0].message.content\n",
    "        try:\n",
    "            sorted_indices = [int(x[0]) for x in gpt_response_text.split('\\n')[:3]]\n",
    "            sorted_texts = [model_outputs[index-1] for index in sorted_indices]\n",
    "            return sorted_texts            \n",
    "        except:\n",
    "            try:\n",
    "                x = json.loads('{ \"x\":'+gpt_response_text.replace(\"'\", '\"')+'}')['x']\n",
    "            except:\n",
    "                x = None\n",
    "            if x is not None and isinstance(x, list) and len(x) == 3:\n",
    "                sorted_texts = x\n",
    "            else:\n",
    "                print('Error parsing GPT')\n",
    "                print(gpt_response_text)\n",
    "                print('')\n",
    "                return model_outputs\n",
    "\n",
    "    # return \"Не удалось найти триплеты.\"\n",
    "    # если нет триплетов, то означает, что улучшить не получилось, ответ не меняется\n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [11:44<00:00,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдены знания в {'ft': 40, 'ftpp': 33, 'gt': 63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_cnt = {'ft': 0, 'ftpp': 0, 'gt': 0}\n",
    "\n",
    "df['llm_reranked_ft'] = None\n",
    "df['llm_reranked_ftpp'] = None\n",
    "df['llm_reranked_gt'] = None\n",
    "\n",
    "for index in tqdm(df[df.uniq_count > 1].index):\n",
    "    query = df.loc[index, 'question']\n",
    "    output_texts = [df.loc[index, 'rag_0'], df.loc[index, 'rag_1'], df.loc[index, 'rag_2']]\n",
    "\n",
    "    for k, query_engine in query_engines.items():\n",
    "        response = query_engine.query(query)\n",
    "        if response.source_nodes:\n",
    "            reranked_outputs = rerank_outputs_llm(query, output_texts, response)\n",
    "            success_cnt[k] += 1\n",
    "        else:\n",
    "            reranked_outputs = output_texts\n",
    "        df.loc[index, f'llm_reranked_{k}'] = reranked_outputs[0]\n",
    "\n",
    "df.to_csv(dataset_path, index=False)\n",
    "\n",
    "print(f'Найдены знания в {success_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количесво изменений ответов:\n",
      "k: 0\n",
      "k: 0\n",
      "k: 0\n"
     ]
    }
   ],
   "source": [
    "print('Количесво изменений ответов:')\n",
    "for k in query_engines.keys():\n",
    "    x = ((df.uniq_count > 1) & (df.rag_0 != df[f'llm_reranked_{k}'])).sum()\n",
    "    print(f'k: {x}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
