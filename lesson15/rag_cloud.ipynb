{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c034d957-cc6d-4914-98ff-7468d7306567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install transformers==4.38.2\n",
    "# %pip install peft==0.10.0\n",
    "# %pip install sentencepiece==0.2.0\n",
    "# %pip install accelerate==0.28.0\n",
    "# %pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "# %pip install --force-reinstall chromadb==0.4.23 \n",
    "# %pip install --force-reinstall llama_index==0.10.12\n",
    "# %pip install --force-reinstall sentence_transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb6edf9-d471-4934-89b9-de2a351517dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import chromadb\n",
    "from llama_index.core import ServiceContext, StorageContext\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, GenerationConfig\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd6ff7-89fa-4298-9c00-e59cef19a55e",
   "metadata": {},
   "source": [
    "Иницилизируем модель для получения эмббедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b080ef-9bd7-4692-9862-22e3473d9a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformerEmbeddingFunction(model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "                                                device='cpu'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4ee6f-c9a9-4791-b1ae-e307fbf7734a",
   "metadata": {},
   "source": [
    "Создаем коллекцию в векторном хранилище"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c032439-3867-42b1-876c-a076a36e5c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=RAG)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(\"RAG\", embedding_function=embed_model,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    "    )\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a516edf-e742-457f-9416-37d21060d0c2",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cb3cc3-a598-44f3-9df8-f058899634c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file_path = \"triples_ft_pp.jsonl\"\n",
    "file_path = \"data/movie_ground_truth.jsonl\" # больше данных - больше вариативность\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99829661-94b0-435d-bade-e842fbb26447",
   "metadata": {},
   "source": [
    "Подготоавливаем данные для загрузки в векторную бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402990c0-f2d8-45fa-a363-2038b9d82531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i_text in data:\n",
    "    i_text = json.loads(i_text)\n",
    "    documents.append(i_text['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c35c9c-7a29-4d59-8611-c6c878cd5ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = [{'subject': 'movie'} for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7156ef60-7a9d-42b0-be9f-7b2e8e058dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = ['id'+str(collection.count()+i+1) for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1479c5-235f-4b12-9b88-5ba3506a40a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee25d7f-e2de-4063-8b3d-5cc4b0cd86ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"openchat/openchat-3.5-0106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef590ad-c177-40ec-bd07-9deb7b413cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.mps' from '/opt/anaconda3/envs/llama/lib/python3.9/site-packages/torch/mps/__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bdeaac7-5f2d-4e9e-af5b-c99c2c452b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████| 3/3 [00:48<00:00, 16.01s/it]\n",
      "/opt/anaconda3/envs/llama/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/llama/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch_device = \"mps\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             pad_token_id=tokenizer.eos_token_id).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db086151-4b5e-47cf-be4d-07b1a2cd4849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:10.223118Z",
     "iopub.status.busy": "2024-04-05T21:41:10.222412Z",
     "iopub.status.idle": "2024-04-05T21:41:10.234974Z",
     "shell.execute_reply": "2024-04-05T21:41:10.233776Z",
     "shell.execute_reply.started": "2024-04-05T21:41:10.223083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.generation_config = GenerationConfig(\n",
    "#        do_sample=True,\n",
    "#        top_k=50,\n",
    "#        top_p=0.95,\n",
    "#        num_return_sequences=num_return_sequences, \n",
    "#        num_beams=num_beams,\n",
    "#        temperature=0.5\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a486484-f3ad-4ce2-b49b-cc0f81e59d21",
   "metadata": {},
   "source": [
    "Промпт для RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b27f5cc-656c-4fe5-80ba-1b44c587a9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {query}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcbb9b-1b94-4304-8d87-906fc7bfa5bb",
   "metadata": {},
   "source": [
    "Функция для поиска контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ca6145-8f84-4f24-86d1-b63d93a0da57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_context(query):\n",
    "    context_raw = collection.query(query_texts=query, n_results=3)\n",
    "    context = \"\\n\".join(context_raw['documents'][0])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7998c6d-60b0-4b61-b186-e16dd9241a7b",
   "metadata": {},
   "source": [
    "Функция для генерации нескольких ответов модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb652fc-8234-4f37-b145-fb3309960155",
   "metadata": {},
   "source": [
    "Закомментированные параметры - эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa217e68-1d51-4d90-9476-fd0f1cc7f7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_output(context, query):\n",
    "    model_inputs = tokenizer(prompt.format(context=context, query=query), return_tensors='pt').to(torch_device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False, # True,\n",
    "    #top_k=50,\n",
    "    #top_p=0.95,\n",
    "    num_return_sequences=3, #6, \n",
    "    num_beams=3, #6,\n",
    "    temperature=None\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for i, output in enumerate(sample_outputs):\n",
    "        result.append(tokenizer.decode(output, skip_special_tokens=True).split(\"Answer:\")[1].strip().split(\"\\n\")[0].strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36c68aa-d237-4b1b-a2bb-37303cf3714a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_output_texts(query: str) -> List[str]:\n",
    "    context = get_context(query)\n",
    "    output_texts = get_model_output(context, query)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b74b2-0578-41b5-a8ff-7b25a77acc29",
   "metadata": {},
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2644d57f-e96b-47b3-b5f6-7e9c30b90091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu,',\n",
       " 'A Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu',\n",
       " 'Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_texts(\"What is a Spirited Away?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192300ff-3f8c-44a0-83a8-7bc9c29969e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01364411-585e-4e04-aa72-3d07a7ec12eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "294a0257-c0ff-4036-a76c-1c3e6b064494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:16.143374Z",
     "iopub.status.busy": "2024-04-05T21:41:16.142563Z",
     "iopub.status.idle": "2024-04-05T21:41:16.159769Z",
     "shell.execute_reply": "2024-04-05T21:41:16.158695Z",
     "shell.execute_reply.started": "2024-04-05T21:41:16.143341Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('eval_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a8aad8f-4cb7-429a-8545-5e22c7cb60d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:16.161785Z",
     "iopub.status.busy": "2024-04-05T21:41:16.160812Z",
     "iopub.status.idle": "2024-04-05T21:41:16.172040Z",
     "shell.execute_reply": "2024-04-05T21:41:16.171092Z",
     "shell.execute_reply.started": "2024-04-05T21:41:16.161720Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = df.head(3)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b2da-97b8-4c82-b561-81f27f86f3b9",
   "metadata": {},
   "source": [
    "Получение выходов<br>\n",
    "Тут сделан алгоритм, который запускает модель несколько раз, чтобы выбрать ответ с отличиющимися ответами<br>\n",
    "Но когда температура выключена, то повтор не имеет смысле (закомментирован)<br>\n",
    "Экспериментально, отключение семплинга позволяет beam search выдавать более разнообразные ответы<br>\n",
    "Поэтому закомментирвоано как эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05cb4a57-1c32-44ee-b6f3-f6e999d19621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:51.854709Z",
     "iopub.status.busy": "2024-04-05T21:41:51.853724Z",
     "iopub.status.idle": "2024-04-05T21:52:50.681520Z",
     "shell.execute_reply": "2024-04-05T21:52:50.680Z",
     "shell.execute_reply.started": "2024-04-05T21:41:51.854671Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [10:58<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "def f7(seq):\n",
    "    \"\"\"Remove duplicates from a list, while preserving order \"\"\"\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "data = []\n",
    "for query in tqdm(df.question):\n",
    "    # когда нет семплинга\n",
    "    data.append(get_output_texts(query)[:num_return_sequences]) \n",
    "    \n",
    "    # когда есть семплинг\n",
    "    # max_unique = 0\n",
    "    # best_outputs = [''] * num_return_sequences\n",
    "    # for _ in range(5):\n",
    "    #     outputs = get_output_texts(query)\n",
    "    #     unique_count = len(set(outputs))\n",
    "    #     if unique_count > max_unique:\n",
    "    #         max_unique = unique_count\n",
    "    #         best_outputs = outputs\n",
    "    #         \n",
    "    #     if unique_count >= num_return_sequences:\n",
    "    #         break\n",
    "    #         \n",
    "    #     if unique_count == 1 and max_unique == 1:\n",
    "    #         break\n",
    "    #         \n",
    "    # best_outputs = f7(best_outputs)[:num_return_sequences]\n",
    "    # if len(best_outputs) != num_return_sequences:\n",
    "    #     best_outputs += [best_outputs[-1]] * (num_return_sequences - len(best_outputs))\n",
    "    #        \n",
    "    #data.append(best_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feef824-732f-4b6b-84d7-70d804042d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc544455-a338-4d11-8153-60173eabf3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a875c655-b396-426a-ae9f-157554bef4f0",
   "metadata": {},
   "source": [
    "Сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bf017a-4abd-4ba7-b547-57e06dd9667e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:53:08.193126Z",
     "iopub.status.busy": "2024-04-05T21:53:08.192501Z",
     "iopub.status.idle": "2024-04-05T21:53:08.215239Z",
     "shell.execute_reply": "2024-04-05T21:53:08.214081Z",
     "shell.execute_reply.started": "2024-04-05T21:53:08.193075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [f'rag_{n}' for n in range(num_return_sequences)]\n",
    "data_t = list(map(list, zip(*data)))\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    df[col] = data_t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dbdbb74-ddc0-47e1-80c0-3cecebf1ee94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:53:08.803465Z",
     "iopub.status.busy": "2024-04-05T21:53:08.802438Z",
     "iopub.status.idle": "2024-04-05T21:53:08.842858Z",
     "shell.execute_reply": "2024-04-05T21:53:08.841675Z",
     "shell.execute_reply.started": "2024-04-05T21:53:08.803419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_count\n",
       "2    63\n",
       "3    51\n",
       "1    43\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def uniq_count(r):\n",
    "    return len(set([r['rag_0'], r['rag_1'], r['rag_2']]))\n",
    "\n",
    "df['uniq_count'] = df.apply(uniq_count, axis=1)\n",
    "display(df['uniq_count'].value_counts())\n",
    "\n",
    "df.to_csv('eval_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875df46-2321-4932-9aaa-1ab21b45a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
