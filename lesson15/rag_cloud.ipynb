{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c034d957-cc6d-4914-98ff-7468d7306567",
   "metadata": {
    "tags": []
   },
   "source": [
    "%pip install transformers==4.38.2\n",
    "%pip install peft==0.10.0\n",
    "%pip install sentencepiece==0.2.0\n",
    "%pip install accelerate==0.28.0\n",
    "%pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "%pip install --force-reinstall chromadb==0.4.23 \n",
    "%pip install --force-reinstall llama_index==0.10.12\n",
    "%pip install --force-reinstall sentence_transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb6edf9-d471-4934-89b9-de2a351517dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 12:51:34.245334: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-04 12:51:34.398196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 12:51:34.398261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 12:51:34.418815: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-04 12:51:34.464096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 12:51:35.235905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import chromadb\n",
    "from llama_index.core import ServiceContext, StorageContext\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, set_seed, GenerationConfig\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd6ff7-89fa-4298-9c00-e59cef19a55e",
   "metadata": {},
   "source": [
    "Иницилизируем модель для получения эмббедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b080ef-9bd7-4692-9862-22e3473d9a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformerEmbeddingFunction(model_name=\"BAAI/bge-small-en-v1.5\", \n",
    "                                                device='cuda'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4ee6f-c9a9-4791-b1ae-e307fbf7734a",
   "metadata": {},
   "source": [
    "Создаем коллекцию в векторном хранилище"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c032439-3867-42b1-876c-a076a36e5c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=RAG)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection(\"RAG\", embedding_function=embed_model,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    "    )\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a516edf-e742-457f-9416-37d21060d0c2",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cb3cc3-a598-44f3-9df8-f058899634c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file_path = \"triples_ft_pp.jsonl\"\n",
    "file_path = \"data/movie_ground_truth.jsonl\" # больше данных - больше вариативность\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99829661-94b0-435d-bade-e842fbb26447",
   "metadata": {},
   "source": [
    "Подготоавливаем данные для загрузки в векторную бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402990c0-f2d8-45fa-a363-2038b9d82531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i_text in data:\n",
    "    i_text = json.loads(i_text)\n",
    "    documents.append(i_text['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c35c9c-7a29-4d59-8611-c6c878cd5ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = [{'subject': 'movie'} for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7156ef60-7a9d-42b0-be9f-7b2e8e058dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = ['id'+str(collection.count()+i+1) for i in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1479c5-235f-4b12-9b88-5ba3506a40a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee25d7f-e2de-4063-8b3d-5cc4b0cd86ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"openchat/openchat-3.5-0106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef590ad-c177-40ec-bd07-9deb7b413cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.mps' from '/home/tiv/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/torch/mps/__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bdeaac7-5f2d-4e9e-af5b-c99c2c452b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278a954fd0f24742bce732fc9a5ec1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiv/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/tiv/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_device = \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             pad_token_id=tokenizer.eos_token_id).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db086151-4b5e-47cf-be4d-07b1a2cd4849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:10.223118Z",
     "iopub.status.busy": "2024-04-05T21:41:10.222412Z",
     "iopub.status.idle": "2024-04-05T21:41:10.234974Z",
     "shell.execute_reply": "2024-04-05T21:41:10.233776Z",
     "shell.execute_reply.started": "2024-04-05T21:41:10.223083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.generation_config = GenerationConfig(\n",
    "#        do_sample=True,\n",
    "#        top_k=50,\n",
    "#        top_p=0.95,\n",
    "#        num_return_sequences=num_return_sequences, \n",
    "#        num_beams=num_beams,\n",
    "#        temperature=0.5\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a486484-f3ad-4ce2-b49b-cc0f81e59d21",
   "metadata": {},
   "source": [
    "Промпт для RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b27f5cc-656c-4fe5-80ba-1b44c587a9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {query}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcbb9b-1b94-4304-8d87-906fc7bfa5bb",
   "metadata": {},
   "source": [
    "Функция для поиска контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ca6145-8f84-4f24-86d1-b63d93a0da57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_context(query):\n",
    "    context_raw = collection.query(query_texts=query, n_results=3)\n",
    "    context = \"\\n\".join(context_raw['documents'][0])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7998c6d-60b0-4b61-b186-e16dd9241a7b",
   "metadata": {},
   "source": [
    "Функция для генерации нескольких ответов модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb652fc-8234-4f37-b145-fb3309960155",
   "metadata": {},
   "source": [
    "Закомментированные параметры - эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa217e68-1d51-4d90-9476-fd0f1cc7f7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_output(context, query):\n",
    "    model_inputs = tokenizer(prompt.format(context=context, query=query), return_tensors='pt').to(torch_device)\n",
    "\n",
    "    sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False, # True,\n",
    "    #top_k=50,\n",
    "    #top_p=0.95,\n",
    "    num_return_sequences=3, #6, \n",
    "    num_beams=3, #6,\n",
    "    temperature=None\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for i, output in enumerate(sample_outputs):\n",
    "        result.append(tokenizer.decode(output, skip_special_tokens=True).split(\"Answer:\")[1].strip().split(\"\\n\")[0].strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36c68aa-d237-4b1b-a2bb-37303cf3714a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_output_texts(query: str) -> List[str]:\n",
    "    context = get_context(query)\n",
    "    output_texts = get_model_output(context, query)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b74b2-0578-41b5-a8ff-7b25a77acc29",
   "metadata": {},
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2644d57f-e96b-47b3-b5f6-7e9c30b90091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu,',\n",
       " 'A Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu',\n",
       " 'Spirited Away is a 2001 Japanese animated fantasy film written and directed by Hayao Miyazaki, animated by Studio Ghibli for Tokuma Shoten, Nippon Television Network, Dentsu.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_texts(\"What is a Spirited Away?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192300ff-3f8c-44a0-83a8-7bc9c29969e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01364411-585e-4e04-aa72-3d07a7ec12eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294a0257-c0ff-4036-a76c-1c3e6b064494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:16.143374Z",
     "iopub.status.busy": "2024-04-05T21:41:16.142563Z",
     "iopub.status.idle": "2024-04-05T21:41:16.159769Z",
     "shell.execute_reply": "2024-04-05T21:41:16.158695Z",
     "shell.execute_reply.started": "2024-04-05T21:41:16.143341Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eval_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/projects/ds/nlp-basics/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eval_dataset.csv'"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('eval_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8aad8f-4cb7-429a-8545-5e22c7cb60d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:16.161785Z",
     "iopub.status.busy": "2024-04-05T21:41:16.160812Z",
     "iopub.status.idle": "2024-04-05T21:41:16.172040Z",
     "shell.execute_reply": "2024-04-05T21:41:16.171092Z",
     "shell.execute_reply.started": "2024-04-05T21:41:16.161720Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = df.head(3)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b2da-97b8-4c82-b561-81f27f86f3b9",
   "metadata": {},
   "source": [
    "Получение выходов<br>\n",
    "Тут сделан алгоритм, который запускает модель несколько раз, чтобы выбрать ответ с отличиющимися ответами<br>\n",
    "Но когда температура выключена, то повтор не имеет смысле (закомментирован)<br>\n",
    "Экспериментально, отключение семплинга позволяет beam search выдавать более разнообразные ответы<br>\n",
    "Поэтому закомментирвоано как эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb4a57-1c32-44ee-b6f3-f6e999d19621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:41:51.854709Z",
     "iopub.status.busy": "2024-04-05T21:41:51.853724Z",
     "iopub.status.idle": "2024-04-05T21:52:50.681520Z",
     "shell.execute_reply": "2024-04-05T21:52:50.680Z",
     "shell.execute_reply.started": "2024-04-05T21:41:51.854671Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [10:58<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "def f7(seq):\n",
    "    \"\"\"Remove duplicates from a list, while preserving order \"\"\"\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "data = []\n",
    "for query in tqdm(df.question):\n",
    "    # когда нет семплинга\n",
    "    data.append(get_output_texts(query)[:num_return_sequences]) \n",
    "    \n",
    "    # когда есть семплинг\n",
    "    # max_unique = 0\n",
    "    # best_outputs = [''] * num_return_sequences\n",
    "    # for _ in range(5):\n",
    "    #     outputs = get_output_texts(query)\n",
    "    #     unique_count = len(set(outputs))\n",
    "    #     if unique_count > max_unique:\n",
    "    #         max_unique = unique_count\n",
    "    #         best_outputs = outputs\n",
    "    #         \n",
    "    #     if unique_count >= num_return_sequences:\n",
    "    #         break\n",
    "    #         \n",
    "    #     if unique_count == 1 and max_unique == 1:\n",
    "    #         break\n",
    "    #         \n",
    "    # best_outputs = f7(best_outputs)[:num_return_sequences]\n",
    "    # if len(best_outputs) != num_return_sequences:\n",
    "    #     best_outputs += [best_outputs[-1]] * (num_return_sequences - len(best_outputs))\n",
    "    #        \n",
    "    #data.append(best_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feef824-732f-4b6b-84d7-70d804042d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc544455-a338-4d11-8153-60173eabf3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a875c655-b396-426a-ae9f-157554bef4f0",
   "metadata": {},
   "source": [
    "Сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf017a-4abd-4ba7-b547-57e06dd9667e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:53:08.193126Z",
     "iopub.status.busy": "2024-04-05T21:53:08.192501Z",
     "iopub.status.idle": "2024-04-05T21:53:08.215239Z",
     "shell.execute_reply": "2024-04-05T21:53:08.214081Z",
     "shell.execute_reply.started": "2024-04-05T21:53:08.193075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = [f'rag_{n}' for n in range(num_return_sequences)]\n",
    "data_t = list(map(list, zip(*data)))\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    df[col] = data_t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdbb74-ddc0-47e1-80c0-3cecebf1ee94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:53:08.803465Z",
     "iopub.status.busy": "2024-04-05T21:53:08.802438Z",
     "iopub.status.idle": "2024-04-05T21:53:08.842858Z",
     "shell.execute_reply": "2024-04-05T21:53:08.841675Z",
     "shell.execute_reply.started": "2024-04-05T21:53:08.803419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniq_count\n",
       "2    63\n",
       "3    51\n",
       "1    43\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def uniq_count(r):\n",
    "    return len(set([r['rag_0'], r['rag_1'], r['rag_2']]))\n",
    "\n",
    "df['uniq_count'] = df.apply(uniq_count, axis=1)\n",
    "display(df['uniq_count'].value_counts())\n",
    "\n",
    "df.to_csv('eval_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875df46-2321-4932-9aaa-1ab21b45a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
